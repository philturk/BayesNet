---
title: "Model - Yule Simon for Component Distribution"
author: "Gabrielle Lemire"
date: "3/12/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(rlist)
library(reshape2)
library(rstanarm)
library(boot)
library(poweRlaw) #compare dists
library(GLDEX) #remove zeros
library(VGAM)
# load data
# load objects created in "sampling_sim.R"
sim_dist_100 = read.csv("C://Code//msu//gra//BayesNet//Paper8//sim_dists.csv")

# --------------- MELT ALL PROPORTIONS
melt_all_props = function(data = sim_dist_100){
  library(reshape2)
  # create one master df with the following columns:
  # X - the size of the component
  # variable - which sim it came from
  # value - count of components
  
  beg_prop = seq(from = 1, to = 346, by = 23)
  end_prop = seq(from = 23, to = 368, by = 23)
  samp_prop = seq(from = .95, to = 0.2, by = -0.05)
  df = data.frame()
  df_all_sim = data.frame()
  for (i in 1:length(beg_prop)){
    beg = beg_prop[i]
    end = end_prop[i]
    df = as.data.frame(data[beg:end,])
    df$X = c(1:23) #leave as 1 to 23 because all props should have this component count
    df = melt(df, id.vars="X")
    df_all_sim = rbind(df_all_sim, df)
  }
  return(df_all_sim)
}


# melt dataframe with all proportions and simulations into one master df_all_sim
df_all_sim = melt_all_props(data = sim_dist_100)

# Data for one simulation of prop=.95
data_1 = df_all_sim[1:23,3]
data_1 = data_1[order(-data_1)] #wait why are we ordering this?

# Data for one simulation of prop=.95 adding 1's
data_2 = df_all_sim[1:23,3] + 1
data_2 = data_2[order(-data_2)] #wait why are we ordering this?
```

## Overview of work in this File

While discussing results from running comparisons with the poweRlaw package between four distributions (power law, log normal, exponential and poisson) we found that power law and log normal both fit different parts of the curve better and exponential and poisson have a poor fit. In this file we want to compare power law (PL) and lognormal (LN) to yule-simon (YS) using the VGAM package. We also want to look into a potential implementation of YS with two parameters. 

Outstanding: 
- after solving above issues with weird predictions include all the simulations not just one
- look into another implementation of YS (two params?)
- why is YS model not working for degree distribution (see other Rmd file)?

## Build Models and Pull Important Data

Questions:
- why are we getting NAs from the predictvglm function? (and why are they decreasing as sampling proportion decreases)
- why are we getting NaNs from the predict LN function (with prop 80 and lower)

```{r}
# data_2 = df_all_sim[1:23,3] + 1
# data_2 = data_2[order(-data_2)]
# data = data.frame(comp = 1:23, count = data_2)
## ---shorter version without creating extra df object
# data = data.frame(comp = 1:23, count = data_2[order(-df_all_sim[1:23,3] + 1)])

# --- get first simulation from each proportion to build model with
data_comp = data.frame(comp=1:23)
beg_sim_line = seq(from = 1, to = 36800, by = 2300)
end_sim_line = seq(from = 23, to = 36800, by = 2300)
samp_prop = seq(from = .95, to = 0.2, by = -0.05)
samp_prop_names = c("ninefive", "nine", "eightfive", "eight", "sevenfive", "seven", "sixfive", "six", "fivefive", "five", "fourfive", "four", "threefive", "three", "twofive", "two")

for (i in 1:16){
  # library(reshape2)
  beg = beg_sim_line[i]
  end = end_sim_line[i]
  data_comp[as.character(samp_prop_names[i])] = df_all_sim[beg:end,3] + 1
}

# --- run model on first simulation from each proportion
# --- store information from each model run (prediction responses and summaries)
model_summaries = list()
plot_comparisons = c()
plot_comparisons_loglog = c()
compare_ln_pl = list()
gof_pl = list()
gof_ln = list()

# note to self add ys to column name
for (i in 1:16) {
  # outputs are:
  # data_comp (dataframe): 16*3 new columns with preds from YS, PL, LN for all props
  # model_summaries (list): 16 model summaries from YS for all props
  # model_intercepts_ys
  # model_slopes_ys
  # gof_pl, gof_ln (lists): 16 values for gof of PL and LN models for all props
  # compare_ln_pl (list): test_statistic, one_sided_p_val, two_sided_p_val for comparing LN and PL model (iff x_min is the same, o/w == 0)
  
  
  # loop through column names corresponding to sampling proportions
  col = samp_prop_names[i]
  
  # build model on i'th column of data
  model = VGAM::vglm(data_comp[[as.character(col)]] ~ data_comp$comp, 
                     yulesimon, data = data_comp, trace = TRUE)
  
  # store predicted values -- why do we have NAs? is this something like the xmin thing for powerlaw?
  data_comp[[paste0("response_", as.character(col), "_ys")]] = predictvglm(model, type="response")
  
  # store summary -- seems to be working as desired
  model_summaries[[i]] = summary(model)
  model_intercepts_ys[[i]] = coef(model)[1]
  model_slopes_ys[[i]] = coef(model)[2]

  
  # create PL and LN models and store predictions in df
  model_pl = displ$new(data_comp[[as.character(col)]])
  est_xmin_pl = estimate_xmin(model_pl)
  model_pl$setXmin(est_xmin_pl$xmin)
  model_pl$setPars(est_xmin_pl$pars)
  gof_pl[i] = est_xmin_pl$gof
  data_comp[[paste0("response_", as.character(col), "_pl")]] = dpldis(data_comp$comp, xmin=est_xmin_pl$xmin, alpha=est_xmin_pl$pars)
  
  model_ln = dislnorm$new(data_comp[[as.character(col)]])
  est_xmin_ln = estimate_xmin(model_ln)
  model_ln$setXmin(est_xmin_ln$xmin)
  model_ln$setPars(est_xmin_ln$pars)
  gof_ln[i] = est_xmin_ln$gof
  data_comp[[paste0("response_", as.character(col), "_ln")]] = dpldis(data_comp$comp, xmin=est_xmin_ln$xmin, alpha=est_xmin_ln$pars)

  # store comparison of ln and pl -- works to store list after changing [] to [[]]
  if (est_xmin_pl$xmin==est_xmin_ln$xmin){
      compare_ln_pl[[i]] = c(compare_distributions(model_pl, model_ln)[1], compare_distributions(model_pl, model_ln)[2], compare_distributions(model_pl, model_ln)[3])
  } else {compare_ln_pl[[i]] = 0}
}
```

## Create Visuals With Predicted Values and GOF Values - WIP

### Visuals for Predicted Values

Questions:
- The gof values for the lognormal models are much higher than for power law, however the visuals (for log-log) clearly show that power law (red) is much closer to the values used to build the model (blue).
- Why are the YS predicted values only at the tail? is there a built in x-min?

Note: The yellow is difficult to see but when other colors (black, pink) were attempted it was very difficult to see any of the other values

```{r}
# --------------- PLOT PREDS FOR ALL PROPORTIONS
plot_comparisons = function(df, col){
  # input - df with columns with simulated values and predicted values for yule-simon, powerlaw and lognormal
  # output - a ggplot object graphing all 4 values on one visual
  visual = ggplot() +
    geom_point(aes(x = comp, y = df[[as.character(col)]]), color="blue", data = df) +
    geom_point(aes(x = comp, y = df[[paste0("response_", as.character(col), "_ys")]]), color="green", data = df, alpha=.5) +
    geom_point(aes(x = comp, y = df[[paste0("response_", as.character(col), "_pl")]]),color="red", data = df, alpha = .5) +
    geom_point(aes(x = comp, y = df[[paste0("response_", as.character(col), "_ln")]]),color="yellow", data = df, alpha = .5) +
    xlab("Comp") +
    ylab("Frequency") +
    labs(title = paste("Actual Comp Dist (blue) for proportion", as.character(col), "\n vs Pred Yule-Simon (green) vs Pred PL (red) vs Pred LN (yellow) \n Some rows of Predicted Omitted (unsure why)"))
  return(visual)
}

# --------------- LOG-LOG PLOT PREDS FOR ALL PROPORTIONS
plot_comparisons_loglog = function(df, col){
  # input - df with columns with simulated values and predicted values for yule-simon, powerlaw and lognormal
  # output - a log-log ggplot object graphing all 4 values on one visual
    visual = ggplot() +
    geom_point(aes(x = log(comp), y = log(data_comp[[as.character(col)]])), color="blue", data = data_comp) +
    geom_point(aes(x = log(comp), y = log(data_comp[[paste0("response_", as.character(col), "_ys")]])), color="green", data = data_comp, alpha=.5) +
    geom_point(aes(x = log(comp), y = log(data_comp[[paste0("response_", as.character(col), "_pl")]])),color="red", data = data_comp, alpha = .5) +
    geom_point(aes(x = log(comp), y = log(data_comp[[paste0("response_", as.character(col), "_ln")]])),color="yellow", data = data_comp, alpha = .5) +
    xlab("Comp") +
    ylab("Frequency") +
    labs(title = paste("Loglog of Actual Comp Dist (blue) for proportion", as.character(col), "\n vs Pred Yule-Simon (green) vs Pred PL (red) vs Pred LN (yellow) \n Some rows of Predicted Omitted (unsure why)"))
  return(visual)
}

# create list of ggplot objects with visuals showing predictions for all 16 proportions for simulated data and each of the 3 models
plots = lapply(samp_prop_names, plot_comparisons, df=data_comp)
loglog_plots = lapply(samp_prop_names, plot_comparisons_loglog, df=data_comp)

print(plots)
print(loglog_plots)
```
### Visuals for GOF for Different Models

To Do:
- add gof for YS that is comparable to these below values

```{r}


```

### Visuals for Parameters in Model

Note to self: seems to be estimating two parameters

```{r}
# will use model_summaries
model_summaries[[1]]

# start with intercept and slope
# add std error or make a p-value one
```

## Other Notes 

- We can use *VGAM::plotvglm(model)* to create plots with pearson residuals but the link scale makes it's hard to interpret.
- In the above we're using *predictvglm(model, type="response")* which returns estimates on the level of the outcome, however there are alternative "types" (*predictvglm(model, type="link")* which returns estimates on the scale of the link function and *predictvglm(model, type="terms")* which is rarely used).

**Notes from group meeting on May 21, 2021**: 

zipf law freq vs rank... common for text analytics

-like an indicator __species
-idf is inverse document relative freqncies (idf) -- usually cast as natual log of the ratio of # of docs in corpus / num of docs that contain the term... but if nothing then it contains a 0 ... so ppl will replace with a 1... but th way he teaches it ... polyamorous - a very common term that appears many times in many docs, and the upper extreme is going to be bounded by the ln(idf), and that term would be an indicator term or monogamous (very special and a characteristic signature for that corpus)...

- does it maintain dist, do params change, etc as sample rate changes
- in survival analysis - exp, weibull ,ln, etc... typical sop is likelihood ratio to compare pairs & proc life reg for gof of each model
prob/proc __ metric -- to see what fit is like... generates a prob-prob or quant-quant plot, uses a mod of Kaplan-Meyer to compare points to line...
- Nicole - sow e'd be thinking of cluster size as survival time... 

- do we care about drop off of 1's
- diff sim's

**old notes can probably delete but I'm a hoarder**:

-give understanding of yule-simon family next meeting (what is a vglm, etc) & how it relates to glm/what i've seen already

- big question after will be how to move parameters in this situation into bigger epidemic model

### Websites:
- *Useful for differentiating "link", "response" and "terms" in the predict function of the vglm* https://www.datascienceblog.net/post/machine-learning/interpreting_generalized_linear_models/
- *Explains why ggplot doesn't work in loop* https://stackoverflow.com/questions/31993704/storing-ggplot-objects-in-a-list-from-within-loop-in-r